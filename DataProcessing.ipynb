{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import ast\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy.stats import zscore\n",
    "from collections import defaultdict, Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\gushi\\LTU\\TennisStrokePrediction\n",
      "Index(['match_id', 'Pt', 'Set1', 'Set2', 'Gm1', 'Gm2', 'Pts', 'Gm#', 'TbSet',\n",
      "       'TB?', 'TBpt', 'Svr', 'Ret', 'Serving', '1st', '2nd', 'Notes',\n",
      "       '1stNoLet', '2ndNoLet', '1stSV', '2ndSV', '1stNoSV', '2ndNoSV', '1stIn',\n",
      "       '2ndIn', 'isRally1st', 'isRally2nd', 'Sv1', 'Sv2', 'Rally', 'isAce',\n",
      "       'isUnret', 'isRallyWinner', 'isForced', 'isUnforced', 'isDouble',\n",
      "       'rallyNoSpec', 'rallyNoError', 'rallyNoDirection', 'rallyLen',\n",
      "       'PtWinner', 'isSvrWinner', 'PtsAfter', 'GmW', 'Gm1.1', 'Gm2.1', 'SetW',\n",
      "       'Set1.1', 'Set2.1', 'RevTB', 'TBrev', 'rallyCount'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gushi\\AppData\\Local\\Temp\\ipykernel_104244\\2372044445.py:5: DtypeWarning: Columns (7,12,24,25,26,31,32,33,34,35,45,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, encoding='latin1')\n"
     ]
    }
   ],
   "source": [
    "# Ensure the file exists in the current directory or provide the correct path\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "file_path = 'data/charting-m-points.csv' \n",
    "\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\t\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "Pt                    0\n",
      "Pts                   0\n",
      "TB?                  75\n",
      "Set1                  0\n",
      "Set2                  0\n",
      "Gm1                   0\n",
      "Gm2                   1\n",
      "match_id              0\n",
      "Svr                   0\n",
      "Ret                   0\n",
      "Serving             946\n",
      "Sv1                   0\n",
      "Sv2              205088\n",
      "isAce                 0\n",
      "isUnret              10\n",
      "isRallyWinner        10\n",
      "isForced             10\n",
      "isUnforced            0\n",
      "isDouble              0\n",
      "rallyNoError      44059\n",
      "rallyLen              0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dropped_features = [\"Gm#\", \"TbSet\", \"TBpt\", \"1st\", \"2nd\", \"Notes\", \"1stNoLet\", \"2ndNoLet\", \"1stSV\", \"2ndSV\", \"1stNoSV\", \"2ndNoSV\", \"1stIn\", \"2ndIn\", \"isRally1st\", \"isRally2nd\", \"Rally\", \"rallyNoSpec\", \"rallyNoDirection\", \"PtWinner\", \"isSvrWinner\", \"PtsAfter\", 'GmW', 'Gm1.1', 'Gm2.1', 'SetW', 'Set1.1', 'Set2.1', \"RevTB\", \"TBrev\", \"rallyCount\"]\n",
    "kept_features = [\"Pt\",]\n",
    "processing_features = [ \"Pts\", \"TB?\",  \"Set1\", \"Set2\", \"Gm1\", \"Gm2\", \"match_id\", \"Svr\", \"Ret\", \"Serving\", \"Sv1\", \"Sv2\", \"isAce\", \"isUnret\",\n",
    "                       \"isRallyWinner\", \"isForced\", \"isUnforced\", \"isDouble\", \"rallyNoError\", \"rallyLen\"]\n",
    "\n",
    "data = data.drop(columns=dropped_features, errors='ignore')\n",
    "kept_features_data = data[kept_features].copy()\n",
    "processing_features_data = data[processing_features].copy()\n",
    "data = pd.concat([kept_features_data, processing_features_data], axis=1)\n",
    "print(\"Missing values:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter by player"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_by_player(data, target_player):\n",
    "    \"\"\"\n",
    "    Filters the data for rows where the target player is playing.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The input dataset.\n",
    "    target_player (str): The name of the target player.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Filtered dataset containing only rows where the target player is playing.\n",
    "    \"\"\"\n",
    "    # Select \"match_id\" where target player is playing\n",
    "    selected_match_ids = data.loc[data['Serving'] == target_player, 'match_id'].unique()\n",
    "\n",
    "    # Filter rows in data where \"match_id\" is in the selected match_ids\n",
    "    filtered_data = data[data['match_id'].isin(selected_match_ids)]\n",
    "    \n",
    "    return filtered_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data quality fixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------#\n",
    "\n",
    "def validate_column_types(df):\n",
    "    expected_types = {\n",
    "        'Pt': 'int64', 'Set1': 'int64', 'Set2': 'int64', 'Gm1': 'int64',\n",
    "        'Gm2': 'float64', 'Pts': 'object',\n",
    "        'TB?': 'float64', 'rallyLen': 'int64'\n",
    "    }\n",
    "    for col, expected in expected_types.items():\n",
    "        if col in df.columns and df[col].dtype != expected:\n",
    "            print(f\"Column {col} has type {df[col].dtype}, expected {expected}\")\n",
    "    return df\n",
    "\n",
    "def validate_score_format(df, drop_invalid=True, fill_default=False):\n",
    "    valid_scores = {'0', '15', '30', '40', 'AD'}\n",
    "\n",
    "    # Clean up Pts before split\n",
    "    df['Pts'] = df['Pts'].astype(str).str.strip().str.replace('\\s+', '', regex=True)\n",
    "\n",
    "    # Only keep rows with exactly one dash\n",
    "    valid_split = df['Pts'].str.contains('-') & df['Pts'].str.count('-').eq(1)\n",
    "    df = df[valid_split].copy()\n",
    "\n",
    "    # Split into components\n",
    "    df[['server_score_raw', 'receiver_score_raw']] = df['Pts'].str.split('-', expand=True)\n",
    "\n",
    "    # Identify invalid rows\n",
    "    invalid_mask = (\n",
    "        ~df['server_score_raw'].isin(valid_scores) |\n",
    "        ~df['receiver_score_raw'].isin(valid_scores)\n",
    "    )\n",
    "\n",
    "    if invalid_mask.any():\n",
    "        print(\"Invalid score entries found:\")\n",
    "        print(df.loc[invalid_mask, 'Pts'].drop_duplicates())\n",
    "\n",
    "    df = df[~invalid_mask].copy()\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def validate_set_game_counts(df):\n",
    "    invalid_sets = df[(df['Set1'] > 3) | (df['Set2'] > 3)]\n",
    "    invalid_games = df[(df['Gm1'] > 7) | (df['Gm2'] > 7)]\n",
    "    df = df.drop(invalid_sets.index.union(invalid_games.index))\n",
    "    return df \n",
    "\n",
    "#-------------------------------------------------------------#\n",
    "\n",
    "def validate_tennis_data(df):\n",
    "    df = validate_column_types(df)\n",
    "    df = validate_score_format(df)\n",
    "    df = validate_set_game_counts(df)\n",
    "    return df\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    df['TB?'] = df['TB?'].fillna(0)\n",
    "    df.dropna(subset=['Gm2'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat data\n",
    "- convert serve data and score to be interpreted from target player's perspective\n",
    "- separate shots to ordered 1, 2, 3, and the target variable 4\n",
    "- ensure rallylen incrrement for each shots."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------#\n",
    "\n",
    "def create_is_serving_column(data, target_player): \n",
    "    \"\"\"\n",
    "    Creates a new column \"is_serving\" indicating if the target player is serving.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The input dataset.\n",
    "    target_player (str): The name of the target player.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Updated dataset with the new \"is_serving\" column.\n",
    "    \"\"\"\n",
    "    data['is_serving'] = np.where(data['Serving'] == target_player, 1, 0)\n",
    "    return data\n",
    "\n",
    "def align_score_to_target_perspective(df):\n",
    "    required_cols = ['server_score_raw', 'receiver_score_raw']\n",
    "    for col in required_cols:\n",
    "        if col not in df.columns:\n",
    "            raise KeyError(f\"Column '{col}' not found. Make sure validate_score_format() was called before this step.\")\n",
    "\n",
    "    score_map = {'0': 0, '15': 1, '30': 2, '40': 3, 'AD': 4}\n",
    "\n",
    "    df['server_score'] = df['server_score_raw'].map(score_map)\n",
    "    df['receiver_score'] = df['receiver_score_raw'].map(score_map)\n",
    "\n",
    "    # Drop any rows that failed mapping\n",
    "    df = df.dropna(subset=['server_score', 'receiver_score'])\n",
    "\n",
    "    flip_mask = df['is_serving'] == 0\n",
    "    df['player_score'] = df['server_score'].where(~flip_mask, df['receiver_score'])\n",
    "    df['opponent_score'] = df['receiver_score'].where(~flip_mask, df['server_score'])\n",
    "    \n",
    "    # Clean up\n",
    "    df.drop(columns=['server_score_raw', 'receiver_score_raw'], inplace=True, errors='ignore')\n",
    "\n",
    "    return df\n",
    "\n",
    "def convert_set_game_count(df, target_player):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Sum sets and games to get total played in the match so far\n",
    "    df['setCount'] = df['Set1'] + df['Set2']\n",
    "    df['gameCount'] = df['Gm1'] + df['Gm2']\n",
    "\n",
    "    # Identify the player number (1 or 2) for the target player per match\n",
    "    is_target_player1 = (\n",
    "        ((df['Svr'] == 1) & (df['Serving'] == target_player)) |\n",
    "        ((df['Svr'] == 2) & (df['Serving'] != target_player))\n",
    "    )\n",
    "\n",
    "    # Assign set/game counts from the target player's perspective\n",
    "    df['set_target'] = np.where(is_target_player1, df['Set1'], df['Set2'])\n",
    "    df['set_opponent'] = np.where(is_target_player1, df['Set2'], df['Set1'])\n",
    "    df['gm_target'] = np.where(is_target_player1, df['Gm1'], df['Gm2'])\n",
    "    df['gm_opponent'] = np.where(is_target_player1, df['Gm2'], df['Gm1'])\n",
    "\n",
    "    return df\n",
    "\n",
    "#-------------------------------------------------------------#\n",
    "\n",
    "def reformat_data(df, target_player):\n",
    "    df = create_is_serving_column(df, target_player)\n",
    "    df = align_score_to_target_perspective(df)\n",
    "    df = convert_set_game_count(df, target_player)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define shot types to be mapped for our unforced error and winners array\n",
    "shot_types = [\n",
    "    'f', 'b',  # groundstrokes\n",
    "    'r', 's',  # slices\n",
    "    'v', 'z',  # volleys\n",
    "    'o', 'p',  # overheads\n",
    "    'u', 'y',  # drop shots\n",
    "    'l', 'm',  # lobs\n",
    "    'h', 'i',  # half-volleys\n",
    "    'j', 'k',  # swinging volleys\n",
    "    #'t', 'q'   # trick shots and unknown shots\n",
    "]\n",
    "\n",
    "# generate combinations with directions 1, 2, 3\n",
    "shot_vocab = {f\"{shot}{n}\": idx for idx, (shot, n) in enumerate(\n",
    "    (s, i) for s in shot_types for i in [1, 2, 3]\n",
    ")}\n",
    "\n",
    "def process_rally_data(df, shot_vocab):\n",
    "    sequence_data = []\n",
    "\n",
    "    # Cumulative counters (non-serve shot totals)\n",
    "    match_rally_count = defaultdict(int)\n",
    "    set_rally_count = defaultdict(int)\n",
    "    game_rally_count = defaultdict(int)\n",
    "\n",
    "    direction_dict = {'1', '2', '3'}\n",
    "    serve_dict = {'4', '5', '6'}\n",
    "\n",
    "    global_sequence_id = 0  # Unique ID for each 4-shot window\n",
    "\n",
    "    for row_idx, row in df.iterrows():\n",
    "        rally = str(row['rallyNoError'])\n",
    "        match_id = row['match_id']\n",
    "        set_id = row['setCount']\n",
    "        game_id = row['gameCount']\n",
    "        isServe = row['Svr'] == 1\n",
    "\n",
    "        if pd.isna(rally) or len(rally) < 2:\n",
    "            continue\n",
    "\n",
    "        tokens = []\n",
    "        match_init = re.match(r'^([a-zA-Z])(\\d+)', rally)\n",
    "        if not match_init:\n",
    "            continue\n",
    "\n",
    "        first_token = match_init.group(1) + match_init.group(2)[0]\n",
    "        if first_token in shot_vocab:\n",
    "            tokens.append(first_token)\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        idx = len(match_init.group(0))\n",
    "\n",
    "        while idx + 2 <= len(rally):\n",
    "            segment = rally[idx:idx + 3]\n",
    "\n",
    "            if re.match(r'^[a-zA-Z]\\d[a-zA-Z]$', segment):\n",
    "                token = segment[0] + segment[1]\n",
    "                if token in shot_vocab:\n",
    "                    tokens.append(token)\n",
    "                else:\n",
    "                    break\n",
    "                idx += 2\n",
    "\n",
    "            elif re.match(r'^[a-zA-Z]\\d\\d$', segment):\n",
    "                token1 = segment[0] + segment[1]\n",
    "                token2 = segment[0] + segment[2]\n",
    "                if segment[1] in direction_dict and token1 in shot_vocab:\n",
    "                    tokens.append(token1)\n",
    "                elif segment[2] in direction_dict and token2 in shot_vocab:\n",
    "                    tokens.append(token2)\n",
    "                else:\n",
    "                    break\n",
    "                idx += 3\n",
    "\n",
    "            elif re.match(r'^[a-zA-Z][a-zA-Z]\\d$', segment):\n",
    "                token = segment[1] + segment[2]\n",
    "                if token in shot_vocab:\n",
    "                    tokens.append(token)\n",
    "                else:\n",
    "                    break\n",
    "                idx += 3\n",
    "\n",
    "            else:\n",
    "                if idx + 1 < len(rally):\n",
    "                    token = rally[idx] + rally[idx + 1]\n",
    "                    if rally[idx].isalpha() and rally[idx + 1] in direction_dict and token in shot_vocab:\n",
    "                        tokens.append(token)\n",
    "                        idx += 2\n",
    "                    else:\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        if not tokens:\n",
    "            continue\n",
    "\n",
    "        # Serve parsing\n",
    "        if not pd.isna(row['Sv1']) and row['Sv1'][0] in serve_dict:\n",
    "            if not pd.isna(row['Sv2']) and row['Sv2'][0] in serve_dict:\n",
    "                full_rally = [row['Sv1'][0], row['Sv2'][0]] + tokens\n",
    "            else:\n",
    "                full_rally = ['0', row['Sv1'][0]] + tokens\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # Final outcome labels\n",
    "        winner_array = np.zeros(48)\n",
    "        unforced_array = np.zeros(48)\n",
    "        final_token = tokens[-1]\n",
    "        shot_idx = shot_vocab.get(final_token)\n",
    "        if shot_idx is not None:\n",
    "            if row['isRallyWinner']:\n",
    "                winner_array[shot_idx] += 1\n",
    "            elif row['isUnforced']:\n",
    "                unforced_array[shot_idx] += 1\n",
    "\n",
    "        current_point_non_serve_count = 0\n",
    "\n",
    "        # Sliding 4-shot window\n",
    "        i = 0 if isServe else 1\n",
    "        while i + 3 < len(full_rally):\n",
    "            shot_window = full_rally[i:i + 4]\n",
    "            global_sequence_id += 1  # <-- Increment for each 4-shot sequence\n",
    "\n",
    "            for j in range(4):\n",
    "                shot_label = shot_window[j]\n",
    "                if j == 3 and shot_label[0] in serve_dict.union({'0'}):\n",
    "                    continue\n",
    "\n",
    "                shot_row = row.to_dict()\n",
    "\n",
    "                shot_row['current_shot'] = shot_label\n",
    "                shot_row['shot_index'] = j + 1\n",
    "                shot_row['shot_id'] = j + 1 \n",
    "                shot_row['sequence_id'] = global_sequence_id  \n",
    "                shot_row['pointRallyLen'] = j + 1\n",
    "\n",
    "                if shot_label[0] not in serve_dict.union({'0'}):\n",
    "                    current_point_non_serve_count += 1\n",
    "                    shot_row['totalMatchRally'] = match_rally_count[match_id] + current_point_non_serve_count\n",
    "                    shot_row['totalSetRally'] = set_rally_count[(match_id, set_id)] + current_point_non_serve_count\n",
    "                    shot_row['totalGameRally'] = game_rally_count[(match_id, game_id)] + current_point_non_serve_count\n",
    "                else:\n",
    "                    shot_row['totalMatchRally'] = match_rally_count[match_id]\n",
    "                    shot_row['totalSetRally'] = set_rally_count[(match_id, set_id)]\n",
    "                    shot_row['totalGameRally'] = game_rally_count[(match_id, game_id)]\n",
    "\n",
    "                shot_row['winner_array'] = winner_array.copy()\n",
    "                shot_row['unforced_array'] = unforced_array.copy()\n",
    "\n",
    "                sequence_data.append(shot_row)\n",
    "\n",
    "            i += 2\n",
    "\n",
    "        # Finalize rally count updates\n",
    "        match_rally_count[match_id] += current_point_non_serve_count\n",
    "        set_rally_count[(match_id, set_id)] += current_point_non_serve_count\n",
    "        game_rally_count[(match_id, game_id)] += current_point_non_serve_count\n",
    "\n",
    "    return pd.DataFrame(sequence_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add compound features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_player_context(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # Score-based features\n",
    "    df['is_deuce'] = ((df['player_score'] == 3) & (df['opponent_score'] == 3)).astype(int)\n",
    "    df['is_break_point'] = ((df['opponent_score'] >= 3) & (df['player_score'] < 3)).astype(int)\n",
    "    df['is_game_point'] = ((df['player_score'] >= 3) & (df['opponent_score'] < 3)).astype(int)\n",
    "    df['point_diff'] = df['player_score'] - df['opponent_score']\n",
    "\n",
    "    # Tie-break indicator\n",
    "    df['is_tiebreak'] = df['TB?'].astype(int)\n",
    "\n",
    "    # Infer best-of format per match_id\n",
    "    max_sets = df.groupby('match_id')[['set_target', 'set_opponent']].max().max(axis=1)\n",
    "    sets_needed_map = (max_sets.apply(lambda x: 3 if x >= 3 else 2)).to_dict()  # Bo5 → 3, Bo3 → 2\n",
    "\n",
    "    # Map sets_needed per row\n",
    "    df['sets_needed'] = df['match_id'].map(sets_needed_map)\n",
    "\n",
    "    def is_set_point(row):\n",
    "        if row['is_tiebreak'] == 0:\n",
    "            return int((row['gm_target'] >= 5) and \n",
    "                       (row['gm_target'] - row['gm_opponent'] >= 1) and \n",
    "                       row['is_game_point'] == 1)\n",
    "        else:\n",
    "            # Tie-break logic\n",
    "            return int((row['player_score'] >= 6) and \n",
    "                       (row['player_score'] - row['opponent_score'] >= 1))\n",
    "\n",
    "    def is_match_point(row):\n",
    "        if row['set_target'] == row['sets_needed'] - 1 and row['set_opponent'] < row['sets_needed'] - 1:\n",
    "            return is_set_point(row)\n",
    "        return 0\n",
    "\n",
    "    df['is_set_point'] = df.apply(is_set_point, axis=1)\n",
    "    df['is_match_point'] = df.apply(is_match_point, axis=1)\n",
    "\n",
    "    # Match pressure score\n",
    "    df['match_pressure_score'] = (\n",
    "        df['is_break_point'] +\n",
    "        df['is_game_point'] +\n",
    "        df['is_deuce'] +\n",
    "        df['is_tiebreak'] +\n",
    "        df['is_match_point'] +\n",
    "        df['is_set_point']\n",
    "    )\n",
    "\n",
    "    # Fatigue estimation\n",
    "    df['match_fatigue'] = (\n",
    "        df['set_target'] * 2 +\n",
    "        df['gm_target'] +\n",
    "        df['totalMatchRally'] / 12\n",
    "    )\n",
    "    df['match_stamina'] = 1 / (1 + df['match_fatigue'])\n",
    "\n",
    "    df['set_fatigue'] = df['totalSetRally'] / 6\n",
    "    df['set_stamina'] = 1 / (1 + df['set_fatigue'])\n",
    "\n",
    "    df['point_fatigue'] = (\n",
    "        df['rallyLen'] / 3 +\n",
    "        df['is_tiebreak'] * 3\n",
    "    )\n",
    "    df['point_stamina'] = 1 / (1 + df['point_fatigue'])\n",
    "\n",
    "    # Clean up\n",
    "    df.drop(columns=['is_tiebreak', 'is_match_point', 'is_set_point', 'sets_needed'], inplace=True, errors='ignore')\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing data for traning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import ast\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "def expand_compound_arrays(df):\n",
    "    def to_array(x):\n",
    "        if isinstance(x, str):\n",
    "            return np.fromstring(x.strip('[]'), sep=' ', dtype=np.float32)\n",
    "        elif isinstance(x, np.ndarray):\n",
    "            return x.astype(np.float32)\n",
    "        else:\n",
    "            raise ValueError(f\"Unsupported type in array column: {type(x)}\")\n",
    "\n",
    "    winner_df = pd.DataFrame(\n",
    "        df['winner_array'].apply(to_array).tolist(),\n",
    "        index=df.index\n",
    "    )\n",
    "    winner_df.columns = [f'winner_{i}' for i in range(winner_df.shape[1])]\n",
    "\n",
    "    unforced_df = pd.DataFrame(\n",
    "        df['unforced_array'].apply(to_array).tolist(),\n",
    "        index=df.index\n",
    "    )\n",
    "    unforced_df.columns = [f'unforced_{i}' for i in range(unforced_df.shape[1])]\n",
    "\n",
    "    return pd.concat([df.drop(columns=['winner_array', 'unforced_array']), winner_df, unforced_df], axis=1)\n",
    "\n",
    "\n",
    "def apply_log_transform(df, columns):\n",
    "    for col in columns:\n",
    "        df[col] = np.log1p(df[col])\n",
    "    return df\n",
    "\n",
    "def apply_log_transform(df, columns, epsilon=1e-6):\n",
    "    for col in columns:\n",
    "        if col in df.columns:\n",
    "            # Ensure no negative or extremely small values\n",
    "            df[col] = df[col].clip(lower=0) + epsilon\n",
    "\n",
    "            # Use log1p for better handling of small values\n",
    "            df[col] = np.log1p(df[col])\n",
    "    return df\n",
    "\n",
    "def clip_outliers(df, columns, lower=0.01, upper=0.99):\n",
    "    for col in columns:\n",
    "        q_low = df[col].quantile(lower)\n",
    "        q_high = df[col].quantile(upper)\n",
    "        df[col] = df[col].clip(lower=q_low, upper=q_high)\n",
    "    return df\n",
    "\n",
    "def scale_features(df, columns):\n",
    "    scaler = StandardScaler()\n",
    "    df[columns] = scaler.fit_transform(df[columns])\n",
    "    return df\n",
    "\n",
    "def encode_shot_columns(df, shot_cols, return_encoders=False):\n",
    "    encoders = {}\n",
    "    for col in shot_cols:\n",
    "        encoded_col = col + '_encoded'\n",
    "        le = LabelEncoder()\n",
    "        df[encoded_col] = le.fit_transform(df[col].astype(str))\n",
    "        encoders[col] = le\n",
    "    return (df, encoders) if return_encoders else df\n",
    "\n",
    "def validate_encoding(df, shot_cols):\n",
    "    return {col: pd.api.types.is_integer_dtype(df[col]) for col in shot_cols}\n",
    "\n",
    "def plot_distributions(df, columns):\n",
    "    for col in columns:\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        sns.histplot(df[col], kde=True, bins=50)\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        plt.xlabel(col)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def data_quality_report(df):\n",
    "    def is_array_like(x):\n",
    "        return isinstance(x.iloc[0], (list, np.ndarray))\n",
    "\n",
    "    # Keep only non-array-like columns\n",
    "    non_array_cols = [col for col in df.columns if not is_array_like(df[col])]\n",
    "\n",
    "    report = pd.DataFrame({\n",
    "        'dtype': df[non_array_cols].dtypes,\n",
    "        'missing_values': df[non_array_cols].isnull().sum(),\n",
    "        'missing_%': (df[non_array_cols].isnull().mean() * 100).round(2),\n",
    "        'unique_values': df[non_array_cols].nunique(),\n",
    "        'sample_values': df[non_array_cols].apply(lambda x: x.dropna().unique()[:3])\n",
    "    })\n",
    "\n",
    "    return report.sort_values('missing_values', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BiLSTM+CNN with label encoder specific pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_lstm_sequences(df, context_cols, shot_col='current_shot', label_encode=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Builds model input (X, y) from the dataset grouped by sequence_id.\n",
    "    Reconstructs the 3-shot input sequence using shot_id ordering.\n",
    "    Returns:\n",
    "        X_seq: np.array of shape (samples, 3, features)\n",
    "        y: np.array of shape (samples,)\n",
    "        shot_encoder: fitted LabelEncoder if label_encode=True, else None\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    import numpy as np\n",
    "\n",
    "    df = df.copy()\n",
    "    shot_encoder = None\n",
    "\n",
    "    if label_encode:\n",
    "        shot_encoder = LabelEncoder()\n",
    "        df[shot_col + '_encoded'] = shot_encoder.fit_transform(df[shot_col].astype(str))\n",
    "        shot_col = shot_col + '_encoded'\n",
    "\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "\n",
    "    grouped = df.groupby('sequence_id')\n",
    "    total = len(grouped)\n",
    "\n",
    "    for i, (_, group) in enumerate(grouped, 1):\n",
    "        group = group.sort_values('shot_id')\n",
    "        if len(group) != 4:\n",
    "            continue\n",
    "\n",
    "        input_sequence = []\n",
    "        for j in range(3):\n",
    "            row = group.iloc[j]\n",
    "            context_feat = row[context_cols].values.astype(np.float32)\n",
    "            shot_code = row[shot_col]\n",
    "            full_input = np.concatenate([context_feat, [shot_code]])\n",
    "            input_sequence.append(full_input)\n",
    "\n",
    "        label = group.iloc[3][shot_col]\n",
    "        X_list.append(input_sequence)\n",
    "        y_list.append(label)\n",
    "\n",
    "        if verbose and i % 5000 == 0:\n",
    "            print(f\"Processed {i}/{total} sequences...\")\n",
    "\n",
    "    print(f\"Finished processing {len(X_list):,} valid sequences.\\n\")\n",
    "    return np.array(X_list), np.array(y_list), shot_encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acutual processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_tennis_data(data, target_player=\"RF\"):\n",
    "    df = data.copy()\n",
    "\n",
    "    steps = [\n",
    "        (\"Filtering by player\", lambda d: filter_data_by_player(d, target_player)),\n",
    "        (\"Handling missing values\", handle_missing_values),\n",
    "        (\"Validating tennis data\", validate_tennis_data),\n",
    "        (\"Reformatting data\", lambda d: reformat_data(d, target_player)),\n",
    "        (\"Processing rally data\", lambda d: process_rally_data(d, shot_vocab=shot_vocab)),\n",
    "        (\"Enriching player context\", enrich_player_context)\n",
    "    ]\n",
    "\n",
    "    print(\"Starting tennis data preprocessing...\")\n",
    "    for i, (desc, func) in enumerate(steps, 1):\n",
    "        print(f\"[{i}/{len(steps)}] {desc}...\")\n",
    "        df = func(df)\n",
    "\n",
    "    df = df.drop(columns=processing_features, errors='ignore')\n",
    "    print(\"Tennis data preprocessing complete.\\n\")\n",
    "    return df\n",
    "\n",
    "def lstm_processing(df):\n",
    "    \"\"\"\n",
    "    Prepares the rally dataset for BiLSTM+CNN training.\n",
    "    Returns:\n",
    "        X_seq: np.array of shape (samples, 3, features)\n",
    "        y: np.array of shape (samples,)\n",
    "        shot_encoder: fitted LabelEncoder for inverse transforms\n",
    "    \"\"\"\n",
    "    log_cols = [\n",
    "        'pointRallyLen', 'totalMatchRally', 'totalSetRally', 'totalGameRally',\n",
    "        'point_diff', 'match_pressure_score',\n",
    "        'match_fatigue', 'match_stamina',\n",
    "        'set_fatigue', 'set_stamina',\n",
    "        'point_fatigue', 'point_stamina'\n",
    "    ]\n",
    "\n",
    "    steps = [\n",
    "        (\"Expanding array columns\", expand_compound_arrays),\n",
    "        (\"Log transforming\", lambda d: apply_log_transform(d, log_cols)),\n",
    "        (\"Cleaning invalid values\", lambda d: clean_invalid_values(d, log_cols)), \n",
    "        (\"Clipping outliers\", lambda d: clip_outliers(d, log_cols)),\n",
    "        (\"Scaling features\", lambda d: scale_features(d, log_cols))\n",
    "    ]\n",
    "\n",
    "    print(\"Starting LSTM data preprocessing...\")\n",
    "    for i, (desc, func) in enumerate(steps, 1):\n",
    "        print(f\"[{i}/{len(steps)}] {desc}...\")\n",
    "        df = func(df)\n",
    "\n",
    "    # Select relevant features for input\n",
    "    context_cols = [\n",
    "        col for col in df.columns\n",
    "        if col not in ['sequence_id', 'shot_index', 'shot_id', 'current_shot']\n",
    "        and not col.endswith('_encoded')\n",
    "        and not isinstance(df[col].iloc[0], (list, np.ndarray))\n",
    "        and pd.api.types.is_numeric_dtype(df[col])\n",
    "    ]\n",
    "\n",
    "    print(f\"[{len(steps)+1}/{len(steps)+1}] Batching sequences for LSTM...\")\n",
    "    X_seq, y, shot_encoder = build_lstm_sequences(df, context_cols, shot_col='current_shot', label_encode=True)\n",
    "    print(f\"LSTM preprocessing complete. Batches: {len(X_seq):,} sequences.\\n\")\n",
    "\n",
    "    return X_seq, y, shot_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting tennis data preprocessing...\n",
      "[1/6] Filtering by player...\n",
      "[2/6] Handling missing values...\n",
      "[3/6] Validating tennis data...\n",
      "Invalid score entries found:\n",
      "7108        0-1\n",
      "7109        1-1\n",
      "7110        1-2\n",
      "7111        2-2\n",
      "7112        2-3\n",
      "          ...  \n",
      "266584    16-17\n",
      "266585    17-17\n",
      "266586    17-18\n",
      "266587    18-18\n",
      "266588    19-18\n",
      "Name: Pts, Length: 77, dtype: object\n",
      "[4/6] Reformatting data...\n",
      "[5/6] Processing rally data...\n",
      "[6/6] Enriching player context...\n",
      "Tennis data preprocessing complete.\n",
      "\n",
      "Total rows after processing: 276,856\n",
      "Unique labels in shot1: ['0' '4' '5' '6' 'b1' 'b2' 'b3' 'f1' 'f2' 'f3' 'h1' 'h2' 'h3' 'i1' 'i2'\n",
      " 'i3' 'j1' 'j2' 'j3' 'k1' 'k2' 'k3' 'l1' 'l2' 'l3' 'm1' 'm2' 'm3' 'o1'\n",
      " 'o2' 'o3' 'p1' 'p2' 'p3' 'r1' 'r2' 'r3' 's1' 's2' 's3' 'u1' 'u2' 'u3'\n",
      " 'v1' 'v2' 'v3' 'y1' 'y2' 'y3' 'z1' 'z2' 'z3']\n",
      "                        dtype  missing_values  missing_%  unique_values  \\\n",
      "Pt                      int64               0        0.0            398   \n",
      "pointRallyLen           int64               0        0.0              4   \n",
      "point_fatigue         float64               0        0.0             39   \n",
      "set_stamina           float64               0        0.0            737   \n",
      "set_fatigue           float64               0        0.0            737   \n",
      "match_stamina         float64               0        0.0           2699   \n",
      "match_fatigue         float64               0        0.0           2716   \n",
      "match_pressure_score    int64               0        0.0              4   \n",
      "point_diff              int64               0        0.0              7   \n",
      "is_game_point           int32               0        0.0              2   \n",
      "is_break_point          int32               0        0.0              2   \n",
      "is_deuce                int32               0        0.0              2   \n",
      "totalGameRally          int64               0        0.0            357   \n",
      "totalSetRally           int64               0        0.0            737   \n",
      "totalMatchRally         int64               0        0.0           2249   \n",
      "sequence_id             int64               0        0.0          69214   \n",
      "is_serving              int64               0        0.0              2   \n",
      "shot_id                 int64               0        0.0              4   \n",
      "shot_index              int64               0        0.0              4   \n",
      "current_shot           object               0        0.0             52   \n",
      "gm_opponent           float64               0        0.0              8   \n",
      "gm_target             float64               0        0.0              8   \n",
      "set_opponent            int64               0        0.0              3   \n",
      "set_target              int64               0        0.0              3   \n",
      "gameCount             float64               0        0.0             15   \n",
      "setCount                int64               0        0.0              5   \n",
      "opponent_score          int64               0        0.0              5   \n",
      "player_score            int64               0        0.0              5   \n",
      "receiver_score          int64               0        0.0              5   \n",
      "server_score            int64               0        0.0              5   \n",
      "point_stamina         float64               0        0.0             38   \n",
      "\n",
      "                                                        sample_values  \n",
      "Pt                                                          [1, 4, 8]  \n",
      "pointRallyLen                                               [1, 2, 3]  \n",
      "point_fatigue                          [0.6666666666666666, 2.0, 1.0]  \n",
      "set_stamina                           [1.0, 0.8571428571428571, 0.75]  \n",
      "set_fatigue            [0.0, 0.16666666666666666, 0.3333333333333333]  \n",
      "match_stamina           [1.0, 0.9230769230769231, 0.8571428571428571]  \n",
      "match_fatigue         [0.0, 0.08333333333333333, 0.16666666666666666]  \n",
      "match_pressure_score                                        [0, 1, 2]  \n",
      "point_diff                                                  [0, 1, 2]  \n",
      "is_game_point                                                  [0, 1]  \n",
      "is_break_point                                                 [0, 1]  \n",
      "is_deuce                                                       [0, 1]  \n",
      "totalGameRally                                              [0, 1, 2]  \n",
      "totalSetRally                                               [0, 1, 2]  \n",
      "totalMatchRally                                             [0, 1, 2]  \n",
      "sequence_id                                                 [1, 2, 3]  \n",
      "is_serving                                                     [1, 0]  \n",
      "shot_id                                                     [1, 2, 3]  \n",
      "shot_index                                                  [1, 2, 3]  \n",
      "current_shot                                               [0, 4, f2]  \n",
      "gm_opponent                                           [0.0, 1.0, 2.0]  \n",
      "gm_target                                             [0.0, 1.0, 2.0]  \n",
      "set_opponent                                                [0, 1, 2]  \n",
      "set_target                                                  [0, 1, 2]  \n",
      "gameCount                                             [0.0, 1.0, 2.0]  \n",
      "setCount                                                    [0, 1, 2]  \n",
      "opponent_score                                              [0, 1, 3]  \n",
      "player_score                                                [0, 2, 1]  \n",
      "receiver_score                                              [0, 1, 2]  \n",
      "server_score                                                [0, 2, 1]  \n",
      "point_stamina           [0.6000000000000001, 0.3333333333333333, 0.5]  \n"
     ]
    }
   ],
   "source": [
    "processed_data = process_tennis_data(data, target_player=\"RF\")\n",
    "\n",
    "data_quality = data_quality_report(processed_data)\n",
    "print(f\"Total rows after processing: {len(processed_data):,}\")\n",
    "print(\"Unique labels in shot1:\", np.unique(processed_data['current_shot']))\n",
    "print(data_quality)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_data.to_csv(\"data/cleaned_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting LSTM data preprocessing...\n",
      "[1/5] Expanding array columns...\n",
      "[2/5] Log transforming...\n",
      "[3/5] Cleaning invalid values...\n",
      "[4/5] Clipping outliers...\n",
      "[5/5] Scaling features...\n",
      "[6/6] Batching sequences for LSTM...\n",
      "Processed 5000/69214 sequences...\n",
      "Processed 10000/69214 sequences...\n",
      "Processed 15000/69214 sequences...\n",
      "Processed 20000/69214 sequences...\n",
      "Processed 25000/69214 sequences...\n",
      "Processed 30000/69214 sequences...\n",
      "Processed 35000/69214 sequences...\n",
      "Processed 40000/69214 sequences...\n",
      "Processed 45000/69214 sequences...\n",
      "Processed 50000/69214 sequences...\n",
      "Processed 55000/69214 sequences...\n",
      "Processed 60000/69214 sequences...\n",
      "Processed 65000/69214 sequences...\n",
      "Finished processing 69,214 valid sequences.\n",
      "\n",
      "LSTM preprocessing complete. Batches: 69,214 sequences.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "# Call the function\n",
    "X_seq, y, shot_encoder = lstm_processing(processed_data)\n",
    "\n",
    "# Save arrays\n",
    "np.savez_compressed('lstm_data.npz', X=X_seq, y=y)\n",
    "\n",
    "# Save LabelEncoder\n",
    "with open('shot_encoder.pkl', 'wb') as f:\n",
    "    pickle.dump(shot_encoder, f)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMpCK1Lt7iODa7s+5h4SExo",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
