{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from scipy.stats import zscore\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### for jupter Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\gushi\\LTU\\TennisStrokePrediction\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gushi\\AppData\\Local\\Temp\\ipykernel_72268\\2372044445.py:5: DtypeWarning: Columns (7,12,24,25,26,31,32,33,34,35,45,51) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(file_path, encoding='latin1')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['match_id', 'Pt', 'Set1', 'Set2', 'Gm1', 'Gm2', 'Pts', 'Gm#', 'TbSet',\n",
      "       'TB?', 'TBpt', 'Svr', 'Ret', 'Serving', '1st', '2nd', 'Notes',\n",
      "       '1stNoLet', '2ndNoLet', '1stSV', '2ndSV', '1stNoSV', '2ndNoSV', '1stIn',\n",
      "       '2ndIn', 'isRally1st', 'isRally2nd', 'Sv1', 'Sv2', 'Rally', 'isAce',\n",
      "       'isUnret', 'isRallyWinner', 'isForced', 'isUnforced', 'isDouble',\n",
      "       'rallyNoSpec', 'rallyNoError', 'rallyNoDirection', 'rallyLen',\n",
      "       'PtWinner', 'isSvrWinner', 'PtsAfter', 'GmW', 'Gm1.1', 'Gm2.1', 'SetW',\n",
      "       'Set1.1', 'Set2.1', 'RevTB', 'TBrev', 'rallyCount'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Ensure the file exists in the current directory or provide the correct path\n",
    "print(\"Current Working Directory:\", os.getcwd())\n",
    "file_path = 'data/charting-m-points.csv' \n",
    "\n",
    "data = pd.read_csv(file_path, encoding='latin1')\n",
    "\t\n",
    "print(data.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values:\n",
      "Pt                    0\n",
      "Set1                  0\n",
      "Set2                  0\n",
      "Gm1                   0\n",
      "Gm2                   1\n",
      "Pts                   0\n",
      "Gm#                   1\n",
      "TB?                  75\n",
      "rallyLen              0\n",
      "match_id              0\n",
      "Svr                   0\n",
      "Ret                   0\n",
      "Serving             946\n",
      "Sv1                   0\n",
      "Sv2              205088\n",
      "isAce                 0\n",
      "isUnret              10\n",
      "isRallyWinner        10\n",
      "isForced             10\n",
      "isUnforced            0\n",
      "isDouble              0\n",
      "rallyNoError      44059\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "dropped_features = [\"TbSet\", \"TBpt\", \"1st\", \"2nd\", \"Notes\", \"1stNoLet\", \"2ndNoLet\", \"1stSV\", \"2ndSV\", \"1stNoSV\", \"2ndNoSV\", \"1stIn\", \"2ndIn\", \"isRally1st\", \"isRally2nd\", \"Rally\", \"rallyNoSpec\", \"rallyNoDirection\", \"PtWinner\", \"isSvrWinner\", \"PtsAfter\", 'GmW', 'Gm1.1', 'Gm2.1', 'SetW', 'Set1.1', 'Set2.1', \"RevTB\", \"TBrev\", \"rallyCount\"]\n",
    "kept_features = [\"Pt\", \"Set1\", \"Set2\", \"Gm1\", \"Gm2\", \"Pts\", \"Gm#\", \"TB?\", \"rallyLen\"]\n",
    "processing_features = [\"match_id\", \"Svr\", \"Ret\", \"Serving\", \"Sv1\", \"Sv2\", \"isAce\", \"isUnret\",\n",
    "                       \"isRallyWinner\", \"isForced\", \"isUnforced\", \"isDouble\", \"rallyNoError\"]\n",
    "\n",
    "data = data.drop(columns=dropped_features, errors='ignore')\n",
    "kept_features_data = data[kept_features].copy()\n",
    "processing_features_data = data[processing_features].copy()\n",
    "data = pd.concat([kept_features_data, processing_features_data], axis=1)\n",
    "print(\"Missing values:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values:\n",
      "Pt                    0\n",
      "Set1                  0\n",
      "Set2                  0\n",
      "Gm1                   0\n",
      "Gm2                   1\n",
      "Pts                   0\n",
      "Gm#                   1\n",
      "TB?                  75\n",
      "rallyLen              0\n",
      "match_id              0\n",
      "Svr                   0\n",
      "Ret                   0\n",
      "Serving             946\n",
      "Sv1                   0\n",
      "Sv2              205088\n",
      "isAce                 0\n",
      "isUnret              10\n",
      "isRallyWinner        10\n",
      "isForced             10\n",
      "isUnforced            0\n",
      "isDouble              0\n",
      "rallyNoError      44059\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data = pd.concat([kept_features_data, processing_features_data], axis=1)\n",
    "print(\"\\nMissing values:\")\n",
    "print(data.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Process deduced features and compount features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_data_by_player(data, target_player):\n",
    "    \"\"\"\n",
    "    Filters the data for rows where the target player is playing.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The input dataset.\n",
    "    target_player (str): The name of the target player.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Filtered dataset containing only rows where the target player is playing.\n",
    "    \"\"\"\n",
    "    # Select \"match_id\" where target player is playing\n",
    "    selected_match_ids = data.loc[data['Serving'] == target_player, 'match_id'].unique()\n",
    "\n",
    "    # Filter rows in data where \"match_id\" is in the selected match_ids\n",
    "    filtered_data = data[data['match_id'].isin(selected_match_ids)]\n",
    "    \n",
    "    return filtered_data\n",
    "\n",
    "#In processing_data create \"Svr\" : 1 if the target player is serving, 0 if the target player is receiving\n",
    "def create_svr_column(data, target_player): \n",
    "    \"\"\"\n",
    "    Creates a new column \"Svr\" in the dataset indicating if the target player is serving.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The input dataset.\n",
    "    target_player (str): The name of the target player.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: Updated dataset with the new \"Svr\" column.\n",
    "    \"\"\"\n",
    "    data['Svr'] = np.where(data['Serving'] == target_player, 1, 0)\n",
    "    return data\n",
    "\n",
    "def align_score_to_target_perspective(df):\n",
    "    score_map = {'0': 0, '15': 1, '30': 2, '40': 3, 'AD': 4}\n",
    "    df[['server_score_raw', 'receiver_score_raw']] = df['Pts'].str.split('-', expand=True)\n",
    "    df['server_score'] = df['server_score_raw'].map(score_map)\n",
    "    df['receiver_score'] = df['receiver_score_raw'].map(score_map)\n",
    "\n",
    "    # Align to target player's perspective\n",
    "    flip_mask = df['Svr'] == 0\n",
    "    df.loc[flip_mask, ['server_score', 'receiver_score']] = df.loc[flip_mask, ['receiver_score', 'server_score']].values\n",
    "    df.loc[flip_mask, ['server_score_raw', 'receiver_score_raw']] = df.loc[flip_mask, ['receiver_score_raw', 'server_score_raw']].values\n",
    "\n",
    "    df.rename(columns={\n",
    "        'server_score': 'player_score',\n",
    "        'receiver_score': 'opponent_score'\n",
    "    }, inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_score_features(df):\n",
    "    df['is_deuce'] = ((df['player_score'] == 3) & (df['opponent_score'] == 3)).astype(int)\n",
    "    df['is_break_point'] = ((df['opponent_score'] >= 3) & (df['player_score'] < 3)).astype(int)\n",
    "    df['is_game_point'] = ((df['player_score'] >= 3) & (df['opponent_score'] < 3)).astype(int)\n",
    "    df['point_diff'] = df['player_score'] - df['opponent_score']\n",
    "    return df\n",
    "\n",
    "def enrich_match_context(df):\n",
    "    df['total_sets_played'] = df['Set1'] + df['Set2']\n",
    "    df['total_games_played'] = df['Gm1'] + df['Gm2']\n",
    "    df['is_tiebreak'] = df['TB?'].astype(int)\n",
    "    df['match_pressure_score'] = (\n",
    "        df['is_break_point'] + df['is_game_point'] + df['is_tiebreak'] + df['is_deuce']\n",
    "    )\n",
    "    return df\n",
    "\n",
    "def estimate_stamina(df):\n",
    "    df['rally_intensity'] = df.groupby(['Set1', 'Set2', 'Gm#'])['rallyLen'].transform('mean')\n",
    "    df['fatigue_index'] = (\n",
    "        df['total_sets_played'] * 2 +\n",
    "        df['total_games_played'] +\n",
    "        df['rallyLen'] / 10 +\n",
    "        df['is_tiebreak'] * 3\n",
    "    )\n",
    "    df['estimated_stamina'] = 1 / (1 + df['fatigue_index'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define shot types to be mapped for our unforced error and winners array\n",
    "shot_types = [\n",
    "    'f', 'b',  # groundstrokes\n",
    "    'r', 's',  # slices\n",
    "    'v', 'z',  # volleys\n",
    "    'o', 'p',  # overheads\n",
    "    'u', 'y',  # drop shots\n",
    "    'l', 'm',  # lobs\n",
    "    'h', 'i',  # half-volleys\n",
    "    'j', 'k',  # swinging volleys\n",
    "    #'t', 'q'   # trick shots and unknown shots\n",
    "]\n",
    "\n",
    "# generate combinations with directions 1, 2, 3\n",
    "shot_vocab = {f\"{shot}{n}\": idx for idx, (shot, n) in enumerate(\n",
    "    (s, i) for s in shot_types for i in [1, 2, 3]\n",
    ")}\n",
    "\n",
    "\n",
    "def process_rally_data(df, shot_vocab):\n",
    "    sequence_data = []\n",
    "    direction_dict = {'1', '2', '3'}\n",
    "    serve_dict={'4','5','6'}\n",
    "\n",
    "    for _, row in df.iterrows():\n",
    "        isServe = row['Svr'] == 1\n",
    "        rally = str(row['rallyNoError'])\n",
    "\n",
    "        if pd.isna(rally) or len(rally) < 2:\n",
    "            continue\n",
    "\n",
    "        debug_logs = []\n",
    "        tokens = []\n",
    "\n",
    "        # First shot: allow 1–2 digits\n",
    "        match = re.match(r'^([a-zA-Z])(\\d+)', rally)\n",
    "        if not match:\n",
    "            continue\n",
    "\n",
    "        first_letter = match.group(1)\n",
    "        digits = match.group(2)[:2]\n",
    "        first_token = first_letter + digits[0]\n",
    "\n",
    "        if first_token in shot_vocab:\n",
    "            tokens.append(first_token)\n",
    "        else:\n",
    "            continue\n",
    "        idx = len(match.group(0))\n",
    "\n",
    "        # Extract remaining shots\n",
    "        while idx + 2 <= len(rally):\n",
    "            segment = rally[idx:idx+3]\n",
    "            debug_logs.append(f\"[{idx}] Segment: '{segment}'\")\n",
    "\n",
    "            if re.match(r'^[a-zA-Z]\\d[a-zA-Z]$', segment):\n",
    "                token = segment[0] + segment[1]\n",
    "                debug_logs.append(f\"[{idx}] Pattern A: {segment}\")\n",
    "\n",
    "                if token in shot_vocab:\n",
    "                    tokens.append(token)\n",
    "\n",
    "                else:\n",
    "                    debug_logs.append(f\"[{idx}] ❌ Invalid token: {token}\")\n",
    "                    break\n",
    "                idx += 2\n",
    "\n",
    "            elif re.match(r'^[a-zA-Z]\\d\\d$', segment):\n",
    "                debug_logs.append(f\"[{idx}] Pattern B: {segment}\")\n",
    "                token1 = segment[0] + segment[1]\n",
    "                token2 = segment[0] + segment[2]\n",
    "\n",
    "                if segment[1] in direction_dict and token1 in shot_vocab:\n",
    "                    tokens.append(token1)\n",
    "\n",
    "                elif segment[2] in direction_dict and token2 in shot_vocab:\n",
    "                    tokens.append(token2)\n",
    "\n",
    "                else:\n",
    "                    debug_logs.append(f\"[{idx}] ❌ Invalid tokens: {token1}, {token2}\")\n",
    "                    break\n",
    "                idx += 3\n",
    "\n",
    "            elif re.match(r'^[a-zA-Z][a-zA-Z]\\d$', segment):\n",
    "                debug_logs.append(f\"[{idx}] Pattern C: {segment}\")\n",
    "                token = segment[1] + segment[2]\n",
    "\n",
    "                if token in shot_vocab:\n",
    "                    tokens.append(token)\n",
    "\n",
    "                else:\n",
    "                    debug_logs.append(f\"[{idx}] ❌ Invalid token: {token}\")\n",
    "                    break\n",
    "                idx += 3\n",
    "\n",
    "            else:\n",
    "                debug_logs.append(f\"[{idx}] Pattern D (Fallback): {segment}\")\n",
    "\n",
    "                if idx + 1 < len(rally):\n",
    "                    ch1, ch2 = rally[idx], rally[idx + 1]\n",
    "                    token = ch1 + ch2\n",
    "\n",
    "                    if ch1.isalpha() and ch2 in direction_dict and token in shot_vocab:\n",
    "                        tokens.append(token)\n",
    "                        idx += 2\n",
    "\n",
    "                    else:\n",
    "                        debug_logs.append(f\"[{idx}] ❌ Invalid fallback token: {token}\")\n",
    "                        break\n",
    "                else:\n",
    "                    break\n",
    "\n",
    "        # Skip rallies with invalid parsing\n",
    "        if any(log.startswith(\"❌\") for log in debug_logs):\n",
    "            print(f\"\\n🔍 Invalid rally at row {row.name}: {rally}\")\n",
    "            for log in debug_logs:\n",
    "                print(log)\n",
    "            continue\n",
    "\n",
    "        # --- Serve Logic ---\n",
    "        if not pd.isna(row['Sv1']) and row['Sv1'][0] in serve_dict:\n",
    "            if not pd.isna(row['Sv2']) and row['Sv2'][0] in serve_dict:\n",
    "                full_rally = [row['Sv1'][0], row['Sv2'][0]] + tokens\n",
    "            else:\n",
    "                full_rally = ['0', row['Sv1'][0]] + tokens\n",
    "        else:\n",
    "            continue\n",
    "\n",
    "        # --- Label Arrays ---\n",
    "        winner_array = np.zeros(48)\n",
    "        unforced_array = np.zeros(48)\n",
    "\n",
    "        final_shot = tokens[-1]\n",
    "        idx = shot_vocab.get(final_shot, None)\n",
    "        if idx is not None:\n",
    "            if row['isRallyWinner']:\n",
    "                winner_array[idx] += 1\n",
    "            elif row['isUnforced']:\n",
    "                unforced_array[idx] += 1\n",
    "\n",
    "        # --- 3-Shot Sequence Construction ---\n",
    "        i = 0 if isServe else 1\n",
    "        while i + 3 < len(full_rally):\n",
    "            new_row = row.to_dict()\n",
    "            new_row['shot1'] = full_rally[i]\n",
    "            new_row['shot2'] = full_rally[i + 1]\n",
    "            new_row['shot3'] = full_rally[i + 2]\n",
    "            new_row['shot4'] = full_rally[i + 3]\n",
    "            new_row['winner_array'] = winner_array.copy()\n",
    "            new_row['unforced_array'] = unforced_array.copy()\n",
    "            sequence_data.append(new_row)\n",
    "            i += 2\n",
    "\n",
    "    return pd.DataFrame(sequence_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_column_types(df):\n",
    "    expected_types = {\n",
    "        'Pt': 'int64', 'Set1': 'int64', 'Set2': 'int64', 'Gm1': 'int64',\n",
    "        'Gm2': 'float64', 'Pts': 'object', 'Gm#': 'object',\n",
    "        'TB?': 'float64', 'rallyLen': 'int64'\n",
    "    }\n",
    "    for col, expected in expected_types.items():\n",
    "        if col in df.columns and df[col].dtype != expected:\n",
    "            print(f\"Column {col} has type {df[col].dtype}, expected {expected}\")\n",
    "    return df\n",
    "\n",
    "def validate_score_format(df):\n",
    "    valid_scores = {'0', '15', '30', '40', 'AD'}\n",
    "    df[['server_score_raw', 'receiver_score_raw']] = df['Pts'].str.split('-', expand=True)\n",
    "    invalid_scores = df[\n",
    "        (~df['server_score_raw'].isin(valid_scores)) |\n",
    "        (~df['receiver_score_raw'].isin(valid_scores))\n",
    "    ]\n",
    "    if not invalid_scores.empty:\n",
    "        print(\"Invalid score entries found:\")\n",
    "        print(invalid_scores[['Pts']].drop_duplicates())\n",
    "    return df[~df.index.isin(invalid_scores.index)]\n",
    "\n",
    "def validate_set_game_counts(df):\n",
    "    invalid_sets = df[(df['Set1'] > 3) | (df['Set2'] > 3)]\n",
    "    invalid_games = df[(df['Gm1'] > 7) | (df['Gm2'] > 7)]\n",
    "    df = df.drop(invalid_sets.index.union(invalid_games.index))\n",
    "    return df\n",
    "\n",
    "def validate_tennis_data(df):\n",
    "    df = validate_column_types(df)\n",
    "    df = validate_score_format(df)\n",
    "    df = validate_set_game_counts(df)\n",
    "    return df\n",
    "\n",
    "def preprocess_numeric_columns(df):\n",
    "    # Clean Gm# to integer\n",
    "    if 'Gm#' in df.columns:\n",
    "        df['Gm#'] = df['Gm#'].apply(lambda x: int(re.match(r'\\d+', str(x)).group()) if re.match(r'\\d+', str(x)) else 0)\n",
    "\n",
    "    # Ensure score columns are integers where applicable\n",
    "    score_cols = ['Set1', 'Set2', 'Gm1', 'Gm2']\n",
    "    for col in score_cols:\n",
    "        df[col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    # Rally length cleanup\n",
    "    if 'rallyLen' in df.columns:\n",
    "        df['rallyLen'] = pd.to_numeric(df['rallyLen'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "    return df\n",
    "\n",
    "def handle_missing_values(df):\n",
    "    df['TB?'] = df['TB?'].fillna(0)\n",
    "    df.dropna(subset=['Gm2', 'Gm#'], inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acutual processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Invalid score entries found:\n",
      "          Pts\n",
      "7108      0-1\n",
      "7109      1-1\n",
      "7110      1-2\n",
      "7111      2-2\n",
      "7112      2-3\n",
      "...       ...\n",
      "266584  16-17\n",
      "266585  17-17\n",
      "266586  17-18\n",
      "266587  18-18\n",
      "266588  19-18\n",
      "\n",
      "[77 rows x 1 columns]\n"
     ]
    }
   ],
   "source": [
    "def process_tennis_data(data, target_player=\"RF\"):\n",
    "    df = data.copy()\n",
    "    df = filter_data_by_player(df, target_player)\n",
    "    df = create_svr_column(df, target_player)\n",
    "    df = validate_tennis_data(df)    \n",
    "    df = align_score_to_target_perspective(df)\n",
    "    df = process_rally_data(df, shot_vocab=shot_vocab)\n",
    "    df = enrich_score_features(df)\n",
    "    df = enrich_match_context(df)\n",
    "    df = estimate_stamina(df)\n",
    "    df = handle_missing_values(df)\n",
    "    df = preprocess_numeric_columns(df)\n",
    "    df = df.drop(columns=processing_features, errors='ignore')\n",
    "    return df\n",
    "\n",
    "processed_data = process_tennis_data(data, target_player=\"RF\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69077 entries, 0 to 69076\n",
      "Data columns (total 30 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Pt                    69077 non-null  int64  \n",
      " 1   Set1                  69077 non-null  int32  \n",
      " 2   Set2                  69077 non-null  int32  \n",
      " 3   Gm1                   69077 non-null  int32  \n",
      " 4   Gm2                   69077 non-null  int32  \n",
      " 5   Pts                   69077 non-null  object \n",
      " 6   Gm#                   69077 non-null  int64  \n",
      " 7   TB?                   69077 non-null  float64\n",
      " 8   rallyLen              69077 non-null  int32  \n",
      " 9   server_score_raw      69077 non-null  object \n",
      " 10  receiver_score_raw    69077 non-null  object \n",
      " 11  player_score          69077 non-null  float64\n",
      " 12  opponent_score        69077 non-null  float64\n",
      " 13  shot1                 69077 non-null  object \n",
      " 14  shot2                 69077 non-null  object \n",
      " 15  shot3                 69077 non-null  object \n",
      " 16  shot4                 69077 non-null  object \n",
      " 17  winner_array          69077 non-null  object \n",
      " 18  unforced_array        69077 non-null  object \n",
      " 19  is_deuce              69077 non-null  int32  \n",
      " 20  is_break_point        69077 non-null  int32  \n",
      " 21  is_game_point         69077 non-null  int32  \n",
      " 22  point_diff            69077 non-null  float64\n",
      " 23  total_sets_played     69077 non-null  int64  \n",
      " 24  total_games_played    69077 non-null  float64\n",
      " 25  is_tiebreak           69077 non-null  int32  \n",
      " 26  match_pressure_score  69077 non-null  int32  \n",
      " 27  rally_intensity       69077 non-null  float64\n",
      " 28  fatigue_index         69077 non-null  float64\n",
      " 29  estimated_stamina     69077 non-null  float64\n",
      "dtypes: float64(8), int32(10), int64(3), object(9)\n",
      "memory usage: 13.2+ MB\n"
     ]
    }
   ],
   "source": [
    "processed_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique labels in shot1: ['b1' 'b2' 'b3' 'f1' 'f2' 'f3' 'h1' 'h2' 'h3' 'i1' 'i2' 'i3' 'j1' 'j2'\n",
      " 'j3' 'k1' 'k3' 'l1' 'l2' 'l3' 'm1' 'm2' 'm3' 'o1' 'o2' 'o3' 'p1' 'p2'\n",
      " 'p3' 'r1' 'r2' 'r3' 's1' 's2' 's3' 'u1' 'u2' 'u3' 'v1' 'v2' 'v3' 'y1'\n",
      " 'y2' 'y3' 'z1' 'z2' 'z3']\n"
     ]
    }
   ],
   "source": [
    "print(\"Unique labels in shot1:\", np.unique(processed_data['shot4']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backup dataset\n",
    "processed_data.to_csv('data/processed_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### quality check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_array_column(df, column):\n",
    "    return df[column].apply(lambda x: np.array(ast.literal_eval(x)) if isinstance(x, str) else np.zeros(48))\n",
    "\n",
    "processed_data['winner_array'] = parse_array_column(processed_data, 'winner_array')\n",
    "processed_data['unforced_array'] = parse_array_column(processed_data, 'unforced_array')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_outliers(df, cols, lower=0.01, upper=0.99):\n",
    "    for col in cols:\n",
    "        q_low = df[col].quantile(lower)\n",
    "        q_high = df[col].quantile(upper)\n",
    "        df[col] = df[col].clip(q_low, q_high)\n",
    "    return df\n",
    "\n",
    "numerical_cols = [\n",
    "    'player_score', 'opponent_score', 'point_diff', 'rallyLen',\n",
    "    'rally_intensity', 'fatigue_index', 'estimated_stamina',\n",
    "    'total_sets_played', 'total_games_played', 'match_pressure_score'\n",
    "]\n",
    "processed_data = clip_outliers(processed_data, numerical_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "\n",
    "shot_columns = ['shot1', 'shot2', 'shot3', 'shot4']\n",
    "label_encoder = LabelEncoder()\n",
    "for col in shot_columns:\n",
    "    processed_data[col + '_encoded'] = label_encoder.fit_transform(processed_data[col])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "processed_data[numerical_cols] = scaler.fit_transform(processed_data[numerical_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cols = ['is_deuce', 'is_break_point', 'is_game_point', 'is_tiebreak']\n",
    "\n",
    "X_seq = []\n",
    "features = processed_data[numerical_cols + binary_cols].values\n",
    "shot1 = processed_data['shot1_encoded'].values\n",
    "shot2 = processed_data['shot2_encoded'].values\n",
    "y = processed_data['target_class'].values\n",
    "\n",
    "for f, s1, s2 in zip(features, shot1, shot2):\n",
    "    t1 = np.concatenate(([s1], f))\n",
    "    t2 = np.concatenate(([s2], f))\n",
    "    X_seq.append([t1, t2])\n",
    "\n",
    "X_seq = np.array(X_seq)  # shape: (samples, 2, input_size)\n",
    "print(\"RNN input shape:\", X_seq.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nicho\\anaconda3\\envs\\diffusion-env\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [09:58:07] WARNING: C:\\b\\abs_90_bwj_86a\\croot\\xgboost-split_1724073762025\\work\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.5614722819676681\n",
      "Test Accuracy: 0.40525914105321587\n",
      "Important features: ['rallyLen' 'shot3' 'winner_0' 'winner_1' 'winner_2' 'winner_3' 'winner_4'\n",
      " 'winner_5' 'winner_12' 'winner_13' 'winner_14' 'winner_15' 'winner_17'\n",
      " 'winner_18' 'winner_20' 'winner_24' 'winner_26' 'winner_27' 'winner_38'\n",
      " 'winner_42' 'winner_43' 'winner_44' 'unforced_0' 'unforced_1'\n",
      " 'unforced_2' 'unforced_3' 'unforced_4' 'unforced_5' 'unforced_9'\n",
      " 'unforced_10' 'unforced_11' 'unforced_12' 'unforced_13' 'unforced_14'\n",
      " 'unforced_16' 'unforced_17' 'unforced_26' 'unforced_27' 'unforced_29']\n",
      "unforced_0: 0.0386\n",
      "winner_2: 0.0384\n",
      "winner_0: 0.0317\n",
      "unforced_5: 0.0316\n",
      "unforced_1: 0.0310\n",
      "unforced_4: 0.0309\n",
      "winner_27: 0.0263\n",
      "shot3: 0.0250\n",
      "unforced_27: 0.0246\n",
      "unforced_17: 0.0230\n",
      "unforced_2: 0.0225\n",
      "winner_17: 0.0212\n",
      "winner_44: 0.0210\n",
      "winner_3: 0.0198\n",
      "rallyLen: 0.0189\n",
      "winner_12: 0.0179\n",
      "winner_24: 0.0178\n",
      "winner_15: 0.0177\n",
      "winner_26: 0.0173\n",
      "unforced_3: 0.0173\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Copy the data\n",
    "processed_data_xgb = processed_data.copy()\n",
    "\n",
    "# xgboost only accepts numerical and categorical data, so we split the 54 size arrays into one column each\n",
    "winner_df = pd.DataFrame(processed_data_xgb['winner_array'].tolist(), index=processed_data_xgb.index)\n",
    "winner_df.columns = [f'winner_{i}' for i in range(winner_df.shape[1])]\n",
    "\n",
    "unforced_df = pd.DataFrame(processed_data_xgb['unforced_array'].tolist(), index=processed_data_xgb.index)\n",
    "unforced_df.columns = [f'unforced_{i}' for i in range(unforced_df.shape[1])]\n",
    "\n",
    "# Drop the original object columns\n",
    "processed_data_xgb.drop(columns=['winner_array', 'unforced_array'], inplace=True)\n",
    "\n",
    "# Concatenate the unpacked columns\n",
    "processed_data_xgb = pd.concat([processed_data_xgb, winner_df, unforced_df], axis=1)\n",
    "\n",
    "# Step 1: Separate features and target BEFORE encoding\n",
    "X = processed_data_xgb.drop(columns=['shot4'])\n",
    "y_raw = processed_data_xgb['shot4']\n",
    "\n",
    "# Step 2: Train-test split\n",
    "X_train, X_test, y_train_raw, y_test_raw = train_test_split(X, y_raw, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Encode categorical feature columns\n",
    "categorical_cols = ['Gm#', 'shot1', 'shot2', 'shot3']\n",
    "label_encoders = {}\n",
    "\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    all_values = pd.concat([X_train[col], X_test[col]]).astype(str)\n",
    "    le.fit(all_values)\n",
    "    X_train[col] = le.transform(X_train[col].astype(str))\n",
    "    X_test[col] = le.transform(X_test[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Step 4: Encode target column (shot3)\n",
    "le_target = LabelEncoder()\n",
    "le_target.fit(pd.concat([y_train_raw, y_test_raw]))\n",
    "y_train = le_target.transform(y_train_raw)\n",
    "y_test = le_target.transform(y_test_raw)\n",
    "\n",
    "X_train_np = np.array(X_train)\n",
    "y_train_np = np.array(y_train, dtype=np.int32)\n",
    "\n",
    "missing_classes = set(range(48)) - set(np.unique(y_train_np))\n",
    "for cls in missing_classes:\n",
    "    dummy_input = X_train_np[0]  # Just reusing one sample (safe for XGBoost)\n",
    "    X_train_np = np.vstack([X_train_np, dummy_input])\n",
    "    y_train_np = np.append(y_train_np, cls)\n",
    "\n",
    "# Shuffle to avoid the dummy samples sitting at the end\n",
    "X_train_np, y_train_np = shuffle(X_train_np, y_train_np, random_state=42)\n",
    "\n",
    "# Step 5: Train model\n",
    "model = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss', objective='multi:softprob',\n",
    "    num_class=48)\n",
    "model.fit(X_train_np, y_train_np)\n",
    "\n",
    "# Step 6: Evaluate\n",
    "print(\"Train Accuracy:\", model.score(X_train, y_train))\n",
    "print(\"Test Accuracy:\", model.score(X_test, y_test))\n",
    "\n",
    "# Step 1: Get column names\n",
    "feature_names = X.columns.to_numpy()  # shape: (109,)\n",
    "\n",
    "# Step 2: Apply importance mask to columns\n",
    "importances = model.feature_importances_\n",
    "important_features = feature_names[importances > 0.01]\n",
    "print(\"Important features:\", important_features)\n",
    "\n",
    "sorted_indices = np.argsort(importances)[::-1]\n",
    "sorted_features = feature_names[sorted_indices]\n",
    "sorted_importances = importances[sorted_indices]\n",
    "\n",
    "# Top 10 most important\n",
    "for feat, imp in zip(sorted_features[:20], sorted_importances[:20]):\n",
    "    print(f\"{feat}: {imp:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-3 Accuracy: 0.7328800388538125\n"
     ]
    }
   ],
   "source": [
    "# predict top-3 accuracy score\n",
    "\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "\n",
    "# Get full list of labels from the label encoder\n",
    "all_classes = le_target.transform(le_target.classes_)\n",
    "\n",
    "# compute top-3 accuracy\n",
    "top3_acc = top_k_accuracy_score(y_test, model.predict_proba(X_test), k=3, labels=all_classes)\n",
    "print(\"Top-3 Accuracy:\", top3_acc)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMpCK1Lt7iODa7s+5h4SExo",
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
